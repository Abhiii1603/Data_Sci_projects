{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering with a fine-tuned BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (4.19.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (4.62.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (1.20.2)\n",
      "Requirement already satisfied: requests in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: torch in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\phani\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (1.20.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers #Huggingface\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch #pytorch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input 1 = Question\n",
    "Input 2 = Passage/Text\n",
    "Output 1 = Answer\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def question_answer(question, text):\n",
    "    \n",
    "    #tokenize question and text in ids as a pair\n",
    "    input_ids = tokenizer.encode(question, text)\n",
    "    \n",
    "    #string version of tokenized ids\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    \n",
    "    #segment IDs\n",
    "    #first occurence of [SEP] token\n",
    "    sep_idx = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    #number of tokens in segment A - question\n",
    "    num_seg_a = sep_idx+1\n",
    "\n",
    "    #number of tokens in segment B - text\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    \n",
    "    #list of 0s and 1s\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    \n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    \n",
    "    #model output using input_ids and segment_ids\n",
    "    output = model(torch.tensor([input_ids]), token_type_ids=torch.tensor([segment_ids]))\n",
    "    \n",
    "    #reconstructing the answer\n",
    "    answer_start = torch.argmax(output.start_logits)\n",
    "    answer_end = torch.argmax(output.end_logits)\n",
    "\n",
    "    if answer_end >= answer_start:\n",
    "        answer = tokens[answer_start]\n",
    "        for i in range(answer_start+1, answer_end+1):\n",
    "            if tokens[i][0:2] == \"##\":\n",
    "                answer += tokens[i][2:]\n",
    "            else:\n",
    "                answer += \" \" + tokens[i]\n",
    "                \n",
    "    if answer.startswith(\"[CLS]\"):\n",
    "        answer = \"Unable to find the answer to your question.\"\n",
    "    \n",
    "#     print(\"Text:\\n{}\".format(text.capitalize()))\n",
    "#     print(\"\\nQuestion:\\n{}\".format(question.capitalize()))\n",
    "    print(\"\\nAnswer:\\n{}\".format(answer.capitalize()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "Training\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"A neural network is a type of machine learning algorithm that is modeled after the structure of the human brain. \n",
    "It consists of layers of interconnected nodes or neurons, each of which performs a simple computation on its inputs. \n",
    "The output of each neuron is then passed to the next layer of neurons until a final output is produced. \n",
    "Neural networks are used for a wide range of tasks, including image and speech recognition, natural language processing, and predictive analytics. \n",
    "They are especially effective for tasks that involve complex patterns or non-linear relationships between inputs and outputs. \n",
    "One of the key advantages of neural networks is that they can learn and improve over time through a process called training. \n",
    "During training, the weights of the neurons are adjusted based on the error between the predicted output and the actual output, allowing the network to improve its accuracy and performance.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Can neural networks learn and improve over time?\"\n",
    "\n",
    "question_answer(question, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original answer:\n",
      " Hard Rock Cafe\n"
     ]
    }
   ],
   "source": [
    "print(\"Original answer:\\n\", data.loc[data[\"question\"] == question][\"answer\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:\n",
      "4 – 2\n",
      "\n",
      "Answer:\n",
      "4 – 2\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eacae202d025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nDo you want to ask another question based on this text (Y/N)? \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mquestion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nPlease enter your question: \\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "text = input(\"Please enter your text: \\n\")\n",
    "question = input(\"\\nPlease enter your question: \\n\")\n",
    "\n",
    "while True:\n",
    "    question_answer(question, text)\n",
    "    \n",
    "    flag = True\n",
    "    flag_N = False\n",
    "    \n",
    "    while flag:\n",
    "        response = input(\"\\nDo you want to ask another question based on this text (Y/N)? \")\n",
    "        if response[0] == \"Y\":\n",
    "            question = input(\"\\nPlease enter your question: \\n\")\n",
    "            flag = False\n",
    "        elif response[0] == \"N\":\n",
    "            print(\"\\nBye!\")\n",
    "            flag = False\n",
    "            flag_N = True\n",
    "            \n",
    "    if flag_N == True:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "336109dad5676e38bf25ab56de492449c5617d71daf49644f2b376d0220af732"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
